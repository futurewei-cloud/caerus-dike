
# Run under java
java -classpath /build/spark-3.2.0/jars/scala-library-2.12.10.jar:target/scala-2.12/spark-examples_2.12-1.0.jar:lib/dikeclient-1.0-jar-with-dependencies.jar com.github.datasource.tests.DatasourceTests

# Debug of spark
docker exec -it sparkmaster spark-submit --conf "spark.jars.ivy=/build/ivy" 
--conf "spark.driver.extraJavaOptions=-classpath /conf/:/build/spark-3.1.0/jars/*:/spark-select/spark-select/target/scala-2.12/ -agentlib:jdwp=transport=dt_socket,server=y,suspend=y,address=172.18.0.3:5005" --packages com.amazonaws:aws-java-sdk:1.11.853,org.apache.hadoop:hadoop-aws:3.2.0,org.apache.commons:commons-csv:1.8 --jars /spark-select/spark-select/target/scala-2.12/spark-select_2.12-2.1.jar /examples/s3-select.py minioserver

# Run without debugger
docker exec -it sparkmaster spark-submit --conf "spark.jars.ivy=/build/ivy" --conf "spark.driver.extraJavaOptions=-classpath /conf/:/build/spark-3.1.0/jars/*:/spark-select/spark-select/target/scala-2.12/" --packages com.amazonaws:aws-java-sdk:1.11.853,org.apache.hadoop:hadoop-aws:3.2.0,org.apache.commons:commons-csv:1.8 --jars /spark-select/spark-select/target/scala-2.12/spark-select_2.12-2.1.jar /examples/s3-select.py minioserver

# Run python s3 select
docker exec -it sparkmaster spark-submit --conf "spark.jars.ivy=/build/ivy" \
--packages com.amazonaws:aws-java-sdk:1.11.853,org.apache.hadoop:hadoop-aws:3.2.0,org.apache.commons:commons-csv:1.8 \
--jars /spark-select/spark-select/target/scala-2.12/spark-select_2.12-2.1.jar /examples/s3-select.py minioserver

# Run scala application (spark-select)
docker exec -it sparkmaster spark-submit --class SparkTest --conf "spark.jars.ivy=/build/ivy"\
            --packages com.amazonaws:aws-java-sdk:1.11.853,org.apache.hadoop:hadoop-aws:3.2.0,org.apache.commons:commons-csv:1.8 \
            --jars /spark-select/spark-select/target/scala-2.12/spark-select_2.12-2.1.jar \
            /examples/scala/target/scala-2.12/spark-select-examples_2.12-1.0.jar minioserver

# Debug scala application (spark-select)
docker exec -it sparkmaster spark-submit --class SparkTest --conf "spark.jars.ivy=/build/ivy"\
            --conf "spark.driver.extraJavaOptions=-classpath /conf/:/build/spark-3.1.0/jars/*:/spark-select/spark-select/target/scala-2.12/:/examples/scala/target/scala-2.12/ -agentlib:jdwp=transport=dt_socket,server=y,suspend=y,address=172.18.0.3:5005"\
            --packages com.amazonaws:aws-java-sdk:1.11.853,org.apache.hadoop:hadoop-aws:3.2.0,org.apache.commons:commons-csv:1.8\
            --jars /spark-select/spark-select/target/scala-2.12/spark-select_2.12-2.1.jar \
            /examples/scala/target/scala-2.12/spark-select-examples_2.12-1.0.jar minioserver

# Run scala test with new S3 v2 data source
docker exec -it sparkmaster spark-submit --master local \
      --class io.s3.datasource.example.S3DatasourceExample \
      --conf "spark.jars.ivy=/build/ivy" \
      --conf "spark.driver.extraJavaOptions=-classpath /conf/:/build/spark-3.1.0/jars/*:/spark-select/spark-select/target/scala-2.12/:/examples/scala/target/scala-2.12/" \
      --packages com.amazonaws:aws-java-sdk:1.11.853,org.apache.hadoop:hadoop-aws:3.2.0,org.apache.commons:commons-csv:1.8 \
       /examples/scala/target/scala-2.12/spark-examples_2.12-1.0.jar minioserver

# Debug scala test with new S3 v2 data source
docker exec -it sparkmaster spark-submit --master local \
      --class io.s3.datasource.example.S3DatasourceExample \
      --conf "spark.jars.ivy=/build/ivy" \
      --conf "spark.driver.extraJavaOptions=-classpath /conf/:/build/spark-3.1.0/jars/*:/spark-select/spark-select/target/scala-2.12/:/examples/scala/target/scala-2.12/-agentlib:jdwp=transport=dt_socket,server=y,suspend=y,address=172.18.0.3:5005"\
      --packages com.amazonaws:aws-java-sdk:1.11.853,org.apache.hadoop:hadoop-aws:3.2.0,org.apache.commons:commons-csv:1.8 \
       /examples/scala/target/scala-2.12/spark-examples_2.12-1.0.jar minioserver
